# Usage
#   Start:              docker compose up
#   With helpers:       docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml up
#   Stop:               docker compose down
#   Destroy:            docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml down -v --remove-orphans
#   Reset everything:  ./reset.sh

name: ADS-BaaS

services:
  studio:
    hostname: ads-studio
    container_name: ads-studio
    image: supabase/studio:20250113-83c9420
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://ads-studio:3000"]
      timeout: 5s
      interval: 5s
      retries: 3
      start_period: 30s
    depends_on:
      analytics:
        condition: service_healthy
    ports:
      - "3001:3000"
    environment:
      STUDIO_PG_META_URL: http://ads-meta:8080
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DEFAULT_ORGANIZATION_NAME: ${STUDIO_DEFAULT_ORGANIZATION}
      DEFAULT_PROJECT_NAME: ${STUDIO_DEFAULT_PROJECT}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      SUPABASE_URL: http://ads-kong:8000
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL}
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      AUTH_JWT_SECRET: ${JWT_SECRET}
      LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
      LOGFLARE_URL: http://ads-analytics:4000
      NEXT_PUBLIC_ENABLE_LOGS: true
      NEXT_ANALYTICS_BACKEND_PROVIDER: postgres

  kong:
    hostname: ads-kong
    container_name: ads-kong
    image: kong:2.8.1-ubuntu
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "8000:8000/tcp"
      - "8001:8001/tcp"
    volumes:
      - ./volumes/api/kong.yml:/home/kong/temp.yml:ro
      - ./init-kong.sh:/home/kong/init-kong.sh:ro
    depends_on:
      analytics:
        condition: service_healthy
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      DASHBOARD_USERNAME: ${DASHBOARD_USERNAME}
      DASHBOARD_PASSWORD: ${DASHBOARD_PASSWORD}
    user: root
    entrypoint: >
      bash -c 'mkdir -p /var/lib/apt/lists/partial && apt-get update && apt-get install -y gettext-base &&
      envsubst "$$SUPABASE_ANON_KEY $$SUPABASE_SERVICE_KEY $$DASHBOARD_USERNAME $$DASHBOARD_PASSWORD" < /home/kong/temp.yml > /home/kong/kong.yml &&
      /docker-entrypoint.sh kong docker-start'

  auth:
    hostname: ads-auth
    container_name: ads-auth
    image: supabase/gotrue:v2.167.0
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "9999:9999"
    healthcheck:
      test:
        - CMD
        - wget
        - --no-verbose
        - --tries=1
        - --spider
        - "http://ads-auth:9999/health"
      timeout: 5s
      interval: 5s
      retries: 3
    depends_on:
      ads-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      GOTRUE_API_HOST: 0.0.0.0
      GOTRUE_API_PORT: 9999
      API_EXTERNAL_URL: ${API_EXTERNAL_URL}
      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${POSTGRES_PASSWORD}@ads-db:5432/${POSTGRES_DB}
      GOTRUE_SITE_URL: ${SITE_URL}
      GOTRUE_URI_ALLOW_LIST: ${ADDITIONAL_REDIRECT_URLS}
      GOTRUE_DISABLE_SIGNUP: ${DISABLE_SIGNUP}
      GOTRUE_JWT_ADMIN_ROLES: service_role
      GOTRUE_JWT_AUD: authenticated
      GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
      GOTRUE_JWT_EXP: ${JWT_EXPIRY}
      GOTRUE_JWT_SECRET: ${JWT_SECRET}
      GOTRUE_EXTERNAL_EMAIL_ENABLED: ${ENABLE_EMAIL_SIGNUP}
      GOTRUE_EXTERNAL_ANONYMOUS_USERS_ENABLED: ${ENABLE_ANONYMOUS_USERS}
      GOTRUE_MAILER_AUTOCONFIRM: ${ENABLE_EMAIL_AUTOCONFIRM}
      GOTRUE_SMTP_HOST: ${SMTP_HOST}
      GOTRUE_SMTP_PORT: ${SMTP_PORT}
      GOTRUE_SMTP_USER: ${SMTP_USER}
      GOTRUE_SMTP_PASS: ${SMTP_PASS}
      GOTRUE_SMTP_ADMIN_EMAIL: ${SMTP_ADMIN_EMAIL}

  rest:
    hostname: ads-rest
    container_name: ads-rest
    image: postgrest/postgrest:v12.2.0
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://ads-rest:3000/health"]
      interval: 5s
      timeout: 5s
      retries: 3
    depends_on:
      ads-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      PGRST_DB_URI: postgres://authenticator:${POSTGRES_PASSWORD}@ads-db:5432/${POSTGRES_DB}
      PGRST_DB_SCHEMAS: ${PGRST_DB_SCHEMAS}
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_USE_LEGACY_GUCS: "false"
      PGRST_APP_SETTINGS_JWT_SECRET: ${JWT_SECRET}
      PGRST_APP_SETTINGS_JWT_EXP: ${JWT_EXPIRY}
    command:
      - postgrest

  realtime:
    hostname: ads-realtime
    container_name: ads-realtime
    image: supabase/realtime:v2.34.7
    restart: unless-stopped
    networks:
      ADS-BaaS-Corenet:
        aliases:
          - ArivantOne
    ports:
      - "4000:4000"
    volumes:
      - ./volumes/realtime/data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-sSfL", "--head", "-o", "/dev/null", "-H", "Host: ArivantOne", "-H", "X-Tenant-External-Id: ArivantOne", "-H", "Authorization: Bearer ${JWT_SECRET}", "http://localhost:4000/status"]
      timeout: 5s
      interval: 5s
      retries: 3
      start_period: 30s
    depends_on:
      ads-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      PORT: 4000
      DB_HOST: ads-db
      DB_PORT: 5432
      DB_USER: supabase_admin
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: postgres
      DB_AFTER_CONNECT_QUERY: 'SET search_path TO realtime'
      DB_ENC_KEY: supabaserealtime
      API_JWT_SECRET: ${JWT_SECRET}
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      ERL_AFLAGS: -proto_dist inet_tcp
      DNS_NODES: "ads-realtime@ads-realtime.ADS-BaaS-Corenet"
      PROJECT_REF: "ArivantOne"
      TENANT: "ArivantOne"
      TENANT_EXTERNAL_ID: "ArivantOne"
      RLIMIT_NOFILE: "10000"
      APP_NAME: realtime
      SEED_SELF_HOST: true
      RUN_JANITOR: true

  storage:
    hostname: ads-storage
    container_name: ads-storage
    image: supabase/storage-api:v1.14.5
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "5002:5000"
    volumes:
      - ./volumes/storage:/var/lib/storage:Z
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://0.0.0.0:5000/status"]
      interval: 5s
      timeout: 5s
      retries: 3
    depends_on:
      ads-db:
        condition: service_healthy
      rest:
        condition: service_started
      imgproxy:
        condition: service_started
    environment:
      ANON_KEY: ${ANON_KEY}
      SERVICE_KEY: ${SERVICE_ROLE_KEY}
      POSTGREST_URL: http://ads-rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET}
      DATABASE_URL: postgres://supabase_storage_admin:${POSTGRES_PASSWORD}@ads-db:5432/${POSTGRES_DB}
      FILE_SIZE_LIMIT: 52428800
      STORAGE_BACKEND: file
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      TENANT_ID: ${PROJECT_REF}
      AWS_REGION: ${REGION}
      GLOBAL_S3_BUCKET: ${GLOBAL_S3_BUCKET}
      ENABLE_IMAGE_TRANSFORMATION: "true"
      IMGPROXY_URL: http://ads-imgproxy:5001

  imgproxy:
    hostname: ads-imgproxy
    container_name: ads-imgproxy
    image: darthsim/imgproxy:v3.8.0
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    volumes:
      - ./volumes/storage:/var/lib/storage:Z
    healthcheck:
      test:
        [
          "CMD",
          "imgproxy",
          "health"
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      IMGPROXY_BIND: ":5001"
      IMGPROXY_LOCAL_FILESYSTEM_ROOT: /
      IMGPROXY_USE_ETAG: "true"
      IMGPROXY_ENABLE_WEBP_DETECTION: ${IMGPROXY_ENABLE_WEBP_DETECTION}

  meta:
    hostname: ads-meta
    container_name: ads-meta
    image: supabase/postgres-meta:v0.84.2
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "8080:8080"
    depends_on:
      ads-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: ads-db
      PG_META_DB_PORT: 5432
      PG_META_DB_NAME: ${POSTGRES_DB}
      PG_META_DB_USER: supabase_admin
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}

  functions:
    hostname: ads-edge-functions
    container_name: ads-edge-functions
    image: node:18-alpine
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "9000:9000"
    volumes:
      - ./volumes/functions:/usr/src/app:Z
    working_dir: /usr/src/app
    command: ["node", "index.js"]
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    depends_on:
      analytics:
        condition: service_healthy

  analytics:
    hostname: ads-analytics
    container_name: ads-analytics
    image: supabase/logflare:1.4.0
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "9001:4000"
    healthcheck:
      test: 
        - CMD
        - curl
        - "http://ads-analytics:4000/health"
      timeout: 5s
      interval: 5s
      retries: 10
    depends_on:
      ads-db:
        condition: service_healthy
    environment:
      LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
      LOGFLARE_NODE_HOST: ads-analytics
      DB_USERNAME: supabase_admin
      DB_DATABASE: _supabase
      DB_HOSTNAME: ads-db
      DB_PORT: 5432
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_SCHEMA: _analytics
      LOGFLARE_SINGLE_TENANT: true
      LOGFLARE_SUPABASE_MODE: true
      LOGFLARE_MIN_CLUSTER_SIZE: 1
      POSTGRES_BACKEND_URL: postgres://supabase_admin:${POSTGRES_PASSWORD}@ads-db:5432/_supabase
      POSTGRES_BACKEND_SCHEMA: _analytics
      LOGFLARE_FEATURE_FLAG_OVERRIDE: multibackend=true
      ERL_FLAGS: -sname logflare

  ads-db:
    hostname: ads-db
    container_name: ads-db
    image: supabase/postgres:15.8.1.020
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "5432:5432"
    volumes:
      - ./volumes/db/realtime.sql:/docker-entrypoint-initdb.d/migrations/99-realtime.sql:Z
      - ./volumes/db/webhooks.sql:/docker-entrypoint-initdb.d/init-scripts/98-webhooks.sql:Z
      - ./volumes/db/roles.sql:/docker-entrypoint-initdb.d/init-scripts/99-roles.sql:Z
      - ./volumes/db/jwt.sql:/docker-entrypoint-initdb.d/init-scripts/99-jwt.sql:Z
      - ./volumes/db/data:/var/lib/postgresql/data:Z
      - ./volumes/db/_supabase.sql:/docker-entrypoint-initdb.d/migrations/97-_supabase.sql:Z
      - ./volumes/db/logs.sql:/docker-entrypoint-initdb.d/migrations/99-logs.sql:Z
      - ./volumes/db/pooler.sql:/docker-entrypoint-initdb.d/migrations/99-pooler.sql:Z
      - db-config:/etc/postgresql-custom
    healthcheck:
      test: 
        - CMD
        - pg_isready
        - -U
        - postgres
        - -h
        - ads-db
      interval: 5s
      timeout: 5s
      retries: 10
    depends_on:
      vector:
        condition: service_healthy
    environment:
      POSTGRES_HOST: /var/run/postgresql
      PGPORT: 5432
      POSTGRES_PORT: 5432
      PGPASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATABASE: ${POSTGRES_DB}
      POSTGRES_DB: ${POSTGRES_DB}
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXP: ${JWT_EXPIRY}
    command:
      - postgres
      - -c
      - config_file=/etc/postgresql/postgresql.conf
      - -c
      - log_min_messages=fatal

  vector:
    hostname: ads-vector
    container_name: ads-vector
    image: timberio/vector:0.28.1-alpine
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    volumes:
      - ./volumes/logs/vector.toml:/etc/vector/vector.toml:ro
      - ./vector_logs:/var/log/vector
      - ${DOCKER_SOCKET_LOCATION}:/var/run/docker.sock:ro
    healthcheck:
      test: [CMD-SHELL, exit 0]
      timeout: 5s
      interval: 5s
      retries: 1
    environment:
      LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
    command:
      - --config
      - /etc/vector/vector.toml

  supavisor:
    hostname: ads-pooler
    container_name: ads-pooler
    image: supabase/supavisor:1.1.56
    restart: unless-stopped
    networks:
      - ADS-BaaS-Corenet
    ports:
      - "5433:5432"
      - ${POOLER_PROXY_PORT_TRANSACTION}:6543
    volumes:
      - ./volumes/pooler/pooler.exs:/etc/pooler/pooler.exs:ro
    healthcheck:
      test: 
        - CMD
        - curl
        - -sSfL
        - --head
        - -o
        - /dev/null
        - "http://ads-pooler:4000/api/health"
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      ads-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      PORT: 4000
      POSTGRES_PORT: 5432
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DATABASE_URL: ecto://supabase_admin:${POSTGRES_PASSWORD}@ads-db:5432/_supabase
      CLUSTER_POSTGRES: true
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      VAULT_ENC_KEY: ${VAULT_ENC_KEY}
      API_JWT_SECRET: ${JWT_SECRET}
      METRICS_JWT_SECRET: ${JWT_SECRET}
      REGION: local
      ERL_AFLAGS: -proto_dist inet_tcp
      POOLER_TENANT_ID: ${POOLER_TENANT_ID}
      POOLER_DEFAULT_POOL_SIZE: ${POOLER_DEFAULT_POOL_SIZE}
      POOLER_MAX_CLIENT_CONN: ${POOLER_MAX_CLIENT_CONN}
      POOLER_POOL_MODE: transaction

volumes:
  db-config:

networks:
  ADS-BaaS-Corenet:
    name: ADS-BaaS-Corenet
    driver: bridge
    ipam:
      config:
        - subnet: 10.225.0.0/16
    driver_opts:
      com.docker.network.bridge.host_binding_ipv4: "0.0.0.0"
